finalData <- sortedData
}
Totals for each vertical slice
totals <- colSums(finalData)
Determine baseline offset
if (type == 0) {
yOffset <- rep(0, length(totals))
} else if (type == 1) {
yOffset <- -totals / 2
} else if (type == 2) {
n <- length(finalData[,1])
i <- 1:length(finalData[,1])
parts <- (n - i + 1) * finalData
theSums <- colSums(parts)
yOffset <- -theSums / (n + 1)
}
Axis upper and lower bounds
yLower <- min(yOffset)
yUpper <- max(yOffset + totals)
Max, min, and span of weights for each layer
maxRow <- max(rowSums(finalData))
minRow <- min(rowSums(finalData))
rowSpan <- if ( (maxRow - minRow) > 0 ) { maxRow - minRow } else { 1 }
Make the graph.
par(las=1, cex=0.6, bty="n")
plot(0, 0, type="n", xlim=c(1, length(finalData[1,])), ylim=c(yLower, yUpper), xlab=NA, ylab=NA)
for (i in 1:length(finalData[,1])) {
colIndex <- floor( (nColors-2) * ( (maxRow - sum(finalData[i,])) / rowSpan ) ) + 1
polygon(c(1:length(finalData[i,]), length(finalData[i,]):1), c(finalData[i,] + yOffset, rev(yOffset)), col=colors[colIndex], border="#ffffff", lwd=0.2)
Move up to next layer.
yOffset <- yOffset + finalData[i,]
}
}
Helper function to convert negative values to zero
zeroNegatives <- function(x) {
if (x < 0) { return(0) }
else { return(x) }
}
rm(list=ls())
setwd("~/Dropbox/GitRepository/occupydata/")
library("lubridate")
library("sqldf")
source("scripts/areagraph.R")
read in, order, and format data
data = read.csv("data/tumblrFinal.csv", stringsAsFactors=F)
names(data) = tolower(gsub("\\.","",names(data)))
data$date = as.Date(data$datetime)
data = data[order(data$date, decreasing=F),]
data$p1 = ifelse(data$topic==1,1,0)
data$p2 = ifelse(data$topic==2,1,0)
data$p3 = ifelse(data$topic==3,1,0)
data$p4 = ifelse(data$topic==4,1,0)
data$p_pos= ifelse(data$fit=="positive",1,0)
data$p_neg= ifelse(data$fit=="negative",1,0)
data$p_neu= ifelse(data$fit=="neutral",1,0)
normalize variables
normalize = function(x){
x = sqrt(x/max(x))
return(x)
}
data[,10:13] = t(apply(data[,10:13], 1, normalize))
data[,14:15] = t(apply(data[,14:15], 1, normalize))
names(data)
head(data)
viz_data = sqldf("select date,
sum(students) as students,
sum(jobseconomy) as jobseconomy,
sum(healthcare) as healthcare,
sum(ideals) as ideals,
sum(p1) as p_students,
sum(p2) as p_jobseconomy,
sum(p3) as p_healthcare,
sum(p4) as p_ideals,
sum(p_pos) as p_pos,
sum(p_neu) as p_neu,
sum(p_neg) as p_neg
from data
group by date")
viz_data_1 = t(viz_data[,6:9])
names(viz_data_1) = as.Date(viz_data$date)
areaGraph(viz_data_1)
rm(list=ls())
setwd("~/Dropbox/GitRepository/occupydata/")
library("lubridate")
library("sqldf")
source("scripts/areagraph.R")
read in, order, and format data
data = read.csv("data/tumblrFinal.csv", stringsAsFactors=F)
names(data) = tolower(gsub("\\.","",names(data)))
data$date = as.Date(data$datetime)
data = data[order(data$date, decreasing=F),]
data$p1 = ifelse(data$topic==1,1,0)
data$p2 = ifelse(data$topic==2,1,0)
data$p3 = ifelse(data$topic==3,1,0)
data$p4 = ifelse(data$topic==4,1,0)
data$p_pos= ifelse(data$fit=="positive",1,0)
data$p_neg= ifelse(data$fit=="negative",1,0)
data$p_neu= ifelse(data$fit=="neutral",1,0)
normalize variables
normalize = function(x){
x = sqrt(x/max(x))
return(x)
}
data[,10:13] = t(apply(data[,10:13], 1, normalize))
data[,14:15] = t(apply(data[,14:15], 1, normalize))
names(data)
head(data)
viz_data = sqldf("select date,
sum(students) as students,
sum(jobseconomy) as jobseconomy,
sum(healthcare) as healthcare,
sum(ideals) as ideals,
sum(p1) as p_students,
sum(p2) as p_jobseconomy,
sum(p3) as p_healthcare,
sum(p4) as p_ideals,
sum(p_pos) as p_pos,
sum(p_neu) as p_neu,
sum(p_neg) as p_neg
from data
group by date")
viz_data_1 = t(viz_data[,6:9])
names(viz_data_1) = as.Date(viz_data$date)
areaGraph(viz_data_1)
rm(list=ls())
setwd("~/Dropbox/GitRepository/occupydata/")
library("lubridate")
library("sqldf")
source("scripts/areagraph.R")
read in, order, and format data
data = read.csv("data/tumblrFinal.csv", stringsAsFactors=F)
names(data) = tolower(gsub("\\.","",names(data)))
data$date = as.Date(data$datetime)
data = data[order(data$date, decreasing=F),]
data$p1 = ifelse(data$topic==1,1,0)
data$p2 = ifelse(data$topic==2,1,0)
data$p3 = ifelse(data$topic==3,1,0)
data$p4 = ifelse(data$topic==4,1,0)
data$p_pos= ifelse(data$fit=="positive",1,0)
data$p_neg= ifelse(data$fit=="negative",1,0)
data$p_neu= ifelse(data$fit=="neutral",1,0)
normalize variables
normalize = function(x){
x = sqrt(x/max(x))
return(x)
}
data[,10:13] = t(apply(data[,10:13], 1, normalize))
data[,14:15] = t(apply(data[,14:15], 1, normalize))
names(data)
head(data)
viz_data = sqldf("select date,
sum(students) as students,
sum(jobseconomy) as jobseconomy,
sum(healthcare) as healthcare,
sum(ideals) as ideals,
sum(p1) as p_students,
sum(p2) as p_jobseconomy,
sum(p3) as p_healthcare,
sum(p4) as p_ideals,
sum(p_pos) as p_pos,
sum(p_neu) as p_neu,
sum(p_neg) as p_neg
from data
group by date")
viz_data_1 = t(viz_data[,6:9])
names(viz_data_1) = as.Date(viz_data$date)
areaGraph(viz_data_1)
Type 0: stacked area, 1: themeriver, 2: streamgraph
areaGraph <- function(thedata, type=0, smooth=FALSE, nPoints =1000) {
Color palette
nColors <- 10
pal <- colorRampPalette(c("#1F78B4","#"))
colors <- pal(nColors)
Sort the data
if (type == 0) {					# Stacked area
Greatest to least weights
sortedData <- thedata[order(rowSums(thedata), decreasing=TRUE),]
} else if (type ==1 || type == 2) {				# Themeriver or streamgraph
Initialize sorted data frame
sortedData <- thedata[1,]
weights <- rowSums(thedata)
topWeight <- weights[1]
bottomWeight <- weights[1]
if (length(thedata[,1]) > 1) {
Commence sorting. Apparently not most efficient way, but whatever.
for (i in 2:length(thedata[,1])) {
if (topWeight > bottomWeight) {
sortedData <- rbind(sortedData, thedata[i,])
} else {
sortedData <- rbind(thedata[i,], sortedData)
bototmWeight <- bottomWeight + weights[i]
}
}
}
}
Smooth the data
if (smooth) {
Initialize smoothed data. Note: Probably a better way to do this, but it works. [NY]
firstRow <- spline(1:length(sortedData[1,]), sortedData[1,], nPoints)$y
firstRow <- sapply(firstRow, zeroNegatives)
smoothData <- data.frame( rbind(firstRow, rep(0, length(firstRow))) )
smoothData <- smoothData[1,]
Smooth the rest of the data using spline().
if (length(sortedData[,1]) > 1) {
for (i in 2:length(sortedData[,1])) {
newRow <- spline(1:length(sortedData[i,]), sortedData[i,], nPoints)$y
newRow <- sapply(newRow, zeroNegatives)
smoothData <- rbind(smoothData, newRow)
}
}
finalData <- smoothData
} else {
finalData <- sortedData
}
Totals for each vertical slice
totals <- colSums(finalData)
Determine baseline offset
if (type == 0) {
yOffset <- rep(0, length(totals))
} else if (type == 1) {
yOffset <- -totals / 2
} else if (type == 2) {
n <- length(finalData[,1])
i <- 1:length(finalData[,1])
parts <- (n - i + 1) * finalData
theSums <- colSums(parts)
yOffset <- -theSums / (n + 1)
}
Axis upper and lower bounds
yLower <- min(yOffset)
yUpper <- max(yOffset + totals)
Max, min, and span of weights for each layer
maxRow <- max(rowSums(finalData))
minRow <- min(rowSums(finalData))
rowSpan <- if ( (maxRow - minRow) > 0 ) { maxRow - minRow } else { 1 }
Make the graph.
par(las=1, cex=0.6, bty="n")
plot(0, 0, type="n", xlim=c(1, length(finalData[1,])), ylim=c(yLower, yUpper), xlab=NA, ylab=NA)
for (i in 1:length(finalData[,1])) {
colIndex <- floor( (nColors-2) * ( (maxRow - sum(finalData[i,])) / rowSpan ) ) + 1
polygon(c(1:length(finalData[i,]), length(finalData[i,]):1), c(finalData[i,] + yOffset, rev(yOffset)), col=colors[colIndex], border="#ffffff", lwd=0.2)
Move up to next layer.
yOffset <- yOffset + finalData[i,]
}
}
Helper function to convert negative values to zero
zeroNegatives <- function(x) {
if (x < 0) { return(0) }
else { return(x) }
}
